"""
Core AI Agent Logic for the AI Infrastructure Agent.

This module contains the "brain" of the application, embodying the
Model-Context-Protocol (MCP) concept. It is divided into two main
components: the Planner and the Executor.
"""

import json
import openai
from typing import Dict, Any

from api.core.settings import SettingsLoader
from api.core.aws import AWSClient
from api.core.state import StateManager

class Planner:
    """
    The Planner is responsible for interpreting user requests and creating an
    executable plan using an LLM.
    """
    def __init__(self, settings: SettingsLoader, openai_client: openai.OpenAI):
        """
        Initializes the Planner.

        Args:
            settings: A SettingsLoader object containing prompts and configs.
            openai_client: An initialized OpenAI client.
        """
        self.settings = settings
        self.openai_client = openai_client

    def create_plan(self, user_request: str, current_state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Creates an execution plan based on a user request and current state.

        Args:
            user_request: The natural language request from the user.
            current_state: The current state of the infrastructure.

        Returns:
            A dictionary representing the execution plan.
        """
        prompt_template = self.settings.prompts.get('decision-plan-prompt-optimized')
        if not prompt_template:
            raise ValueError("Decision plan prompt template not found.")

        # Assemble the prompt
        final_prompt = prompt_template.format(
            user_request=user_request,
            current_state=json.dumps(current_state, indent=2),
            resource_patterns=json.dumps(self.settings.resource_patterns, indent=2),
            field_mappings=json.dumps(self.settings.field_mappings, indent=2)
        )

        # Make the API call to the LLM
        response = self.openai_client.chat.completions.create(
            model="gpt-4",  # Or use a model from config
            messages=[{"role": "system", "content": final_prompt}],
            response_format={"type": "json_object"}
        )

        # Parse and return the plan
        plan_str = response.choices[0].message.content
        return json.loads(plan_str)

class Executor:
    """
    The Executor is responsible for executing a plan and updating the state.
    """
    def __init__(self, aws_client: AWSClient, state_manager: StateManager):
        """
        Initializes the Executor.

        Args:
            aws_client: An initialized AWSClient.
            state_manager: An initialized StateManager.
        """
        self.aws_client = aws_client
        self.state_manager = state_manager

    def execute_plan(self, plan: Dict[str, Any], current_state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executes a plan and updates the infrastructure state.

        Args:
            plan: The execution plan generated by the Planner.
            current_state: The current state of the infrastructure.

        Returns:
            The final, updated state of the infrastructure.
        """
        for step in plan.get("executionPlan", []):
            action = step.get("action")
            tool = step.get("mcpTool")
            params = step.get("toolParameters", {})

            # Simple dispatcher based on tool name
            # A more robust implementation would use a proper tool registry
            if action == "create":
                if tool == "create-ec2-instance":
                    self.aws_client.create_ec2_instance(**params)
                elif tool == "create-s3-bucket":
                    self.aws_client.create_s3_bucket(**params)
                # Add other tool handlers here...

            # Update state after each successful action
            # This is a simplified example; a real implementation would be more robust
            resource_id = step.get("resourceId")
            if resource_id:
                current_state[resource_id] = {"status": "created", "details": params}

        self.state_manager.save_state(current_state)
        return current_state
